{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Survival of Titanic Passengers\n",
    "\n",
    "Hello! Here we aimed to predict whether the titanic passenger survive or not by looking on the passenger information. The first time that comes into my mind is that 'How cruel!' We have to predict which one survived which one dead. But again, this is for educational purposes, right? So, this information could be useful for improving how we dead with the data so that we could get a higher accuracy, OR by observing the relationship between the features, we might can prevent any future accident. At least we could be aware of that :D\n",
    "<br>\n",
    "<br>\n",
    "The link to the dataset can be found on the following link : https://www.kaggle.com/c/titanic\n",
    "<br>\n",
    "Data Dictionary <br>\n",
    "Variable\tDefinition\tKey <br>\n",
    "survival\tSurvival\t0 = No, 1 = Yes\n",
    "pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "sex\tSex\t\n",
    "Age\tAge in years\t\n",
    "sibsp\t# of siblings / spouses aboard the Titanic\t\n",
    "parch\t# of parents / children aboard the Titanic\t\n",
    "ticket\tTicket number\t\n",
    "fare\tPassenger fare\t\n",
    "cabin\tCabin number\t\n",
    "embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "_cell_guid": "b04d099b-01db-4d49-8e6a-dd485e097fd7",
    "_uuid": "6031aaa1497a4b543eec86e60a228d83426b1c68",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Compulsory Standard Library #################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numbers\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "############ Sklearn pre-processing Library #################\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "############ Sklearn model Library #################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e0f7aaaa-46cd-4593-8eb9-94846f74c54b",
    "_uuid": "ec34335ae822ce17eca31c2b71120d177ce80113"
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vocabulary(filename):\n",
    "    vocabulary = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for l in f:\n",
    "            vocabulary.append(l.strip())\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(words, key):\n",
    "#     vocab = [s for s in words if key in s]\n",
    "    filename = words + '.txt'\n",
    "    with open(filename, mode='w', encoding='utf8') as w:\n",
    "        for i in key:\n",
    "#             print(i)\n",
    "            w.write(str(i))\n",
    "            w.write('\\n')\n",
    "        w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "43ea9df6-c7b2-42ea-837d-eba95225ee38",
    "_uuid": "5acf5804d1fc4352b0729f6a55d337a6aed6497e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "test_df = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "39282ff0-4ec3-46f0-8f03-5fbbd9711cd6",
    "_uuid": "7237f7eb5ce056c5daa30a22076d008a377e9073"
   },
   "source": [
    "## Data Description\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "7cd99fbf-8882-48e8-afa0-8abd14ef5c7d",
    "_uuid": "59c0b7c09dd6538bb8bf210af45302cc0968ebc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Features :  12\n",
      "Train Data Samples :  891\n",
      "Test Data Samples :  418\n"
     ]
    }
   ],
   "source": [
    "print('# of Features : ', train_df.shape[1])\n",
    "print('Train Data Samples : ', train_df.shape[0])\n",
    "print('Test Data Samples : ', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PassengerID : Unique Value\n",
    "Name : Does not contribute to the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "815cd0bf-d321-4aeb-ada4-c75216551589",
    "_uuid": "b0f771c5bea8309209ba2af9e6951bb55ef084c2"
   },
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is for eliminating the 'NaN' value on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nan_eliminate(X_data):\n",
    "    data_mean = np.nanmean(X_data, axis=0)\n",
    "#     for j in range(0,X_data.shape[1]):\n",
    "    for i in range(0,X_data.shape[0]):\n",
    "        if math.isnan(X_data[i]):\n",
    "            X_data[i] = data_mean\n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### 1. One hot encoding\n",
    "#### 2. delete the matrix\n",
    "#### 3. return the X_train matrix\n",
    "\n",
    "def one_hot_encoding(X_data, dummy=True):\n",
    "    one_hot_encoding_data = pd.get_dummies(X_data, dummy_na=dummy)\n",
    "    return one_hot_encoding_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "d9fc787e-b959-47ea-81b0-0bff8e31520f",
    "_uuid": "4b08e6f320644c43f1ae1c6b28f5d99aaba555e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive sample :  342\n",
      "Total negative sample :  549\n",
      "The train data is unbalanced\n"
     ]
    }
   ],
   "source": [
    "# X_train = train_df.iloc[:,2:]\n",
    "y_train = np.array(train_df.iloc[:, 1])\n",
    "y_test = np.array(test_df.iloc[:,1])\n",
    "\n",
    "print('Total positive sample : ', np.sum(y_train == 1))\n",
    "print('Total negative sample : ', np.sum(y_train == 0))\n",
    "print('The train data is unbalanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pclass = one_hot_encoding(train_df.iloc[:,2], dummy=False)\n",
    "sex = one_hot_encoding(train_df.iloc[:,4], dummy=False)\n",
    "sibling = one_hot_encoding(train_df.iloc[:,6], dummy=False)\n",
    "parent = one_hot_encoding(train_df.iloc[:,7], dummy=False)\n",
    "# cabin = one_hot_encoding(train_df.iloc[:,10])\n",
    "embarked = one_hot_encoding(train_df.iloc[:,11], dummy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_original = train_df.iloc[:,5]\n",
    "fare_original = train_df.iloc[:,9]\n",
    "age_previous = nan_eliminate(age_original)\n",
    "fare_previous = nan_eliminate(fare_original)\n",
    "age = []\n",
    "fare = []\n",
    "\n",
    "\n",
    "for i in age_previous:\n",
    "    if i <= 10:\n",
    "        group = 1\n",
    "    elif i <= 20:\n",
    "        group = 2\n",
    "    elif i <= 30:\n",
    "        group = 3\n",
    "    elif i <= 40:\n",
    "        group = 4\n",
    "    elif i <= 50:\n",
    "        group = 5\n",
    "    elif i <= 60:\n",
    "        group = 6\n",
    "    elif i <= 70:\n",
    "        group = 7\n",
    "    else:\n",
    "        group = 8\n",
    "    age.append(group)\n",
    "\n",
    "age = one_hot_encoding(age, dummy=False)\n",
    "for i in fare_previous:\n",
    "    if i <= 100:\n",
    "        fare_group = 1\n",
    "    else:\n",
    "        fare_group = 2\n",
    "        \n",
    "    fare.append(fare_group)\n",
    "fare = one_hot_encoding(fare, dummy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "prefix = ['mr', 'miss', 'mrs', 'master', 'dr']\n",
    "cv = CountVectorizer(lowercase=True, binary=True, token_pattern=token)\n",
    "name_token = cv.fit_transform(train_df[\"Name\"])\n",
    "name_list = cv.get_feature_names()\n",
    "\n",
    "# for i in name_list:\n",
    "#     print(i)\n",
    "\n",
    "freq = np.sum(name_token, axis=0)\n",
    "indices_descending = np.argsort(freq.A1)[::-1]\n",
    "# for i in range(0, len(indices_descending)):\n",
    "#     print(name_list[indices_descending[i]])\n",
    "#     if \"dr\" in name_list[indices_descending[i]]:\n",
    "#         print(name_list[indices_descending[i]],\n",
    "#          '\\t', freq[0, indices_descending[i]])\n",
    "\n",
    "# for i in range(0, len(indices_descending)):\n",
    "#     if \"rose\" in name_list[indices_descending[i]]:\n",
    "#         print(indices_descending[i], name_list[indices_descending[i]])\n",
    "\n",
    "# 1498\n",
    "# 1499\n",
    "# william_alive = 0\n",
    "# william_dead = 0\n",
    "# for i in range(0, len(y_train)):\n",
    "#     if name_token[i, 1498] == 1 and y_train[i] == 1:\n",
    "#         william_alive = william_alive + 1\n",
    "#     elif name_token[i, 1498] == 1 and y_train[i] == 0:\n",
    "#         william_dead = william_dead + 1\n",
    "\n",
    "# print(william_alive, ' ', william_dead)\n",
    "\n",
    "prefix_indices = []\n",
    "for i in range(0,len(name_list)):\n",
    "    for j in range(0, len(prefix)):\n",
    "        if name_list[i] == prefix[j]:\n",
    "            prefix_indices.append(i)\n",
    "\n",
    "# name_token[:, prefix_indices[0]].todense().shape\n",
    "X_name = np.concatenate((name_token[:, prefix_indices[0]].todense(), \n",
    "                         name_token[:, prefix_indices[1]].todense(),\n",
    "                         name_token[:, prefix_indices[2]].todense(),\n",
    "                         name_token[:, prefix_indices[3]].todense(),\n",
    "                         name_token[:, prefix_indices[4]].todense()),\n",
    "                       axis=1)            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "891\n",
      "891\n"
     ]
    }
   ],
   "source": [
    "ticket_cv = CountVectorizer(lowercase=True, binary=True, token_pattern=token, ngram_range=(1,1), min_df=2)\n",
    "ticket_matrices = ticket_cv.fit_transform(train_df[\"Ticket\"])\n",
    "ticket_token = ticket_cv.get_feature_names()\n",
    "print(len(ticket_token))\n",
    "# [i for i in ticket_token]\n",
    "freq_ticket = np.sum(ticket_matrices, axis=0)\n",
    "ticket_indices_descending = np.argsort(freq_ticket.A1)[::-1]\n",
    "\n",
    "new_ticket_token = []\n",
    "# for i in ticket_token:\n",
    "#     if(i.isalpha()):\n",
    "#         ticket_token = [w.replace(i, '99') for w in ticket_token]\n",
    "\n",
    "new_ticket_token = [] \n",
    "for i in ticket_original:     \n",
    "    if(i.isnumeric()):         \n",
    "        new_ticket_token.append(int(i))     \n",
    "    else:         \n",
    "        new_ticket_token.append(99)          \n",
    "\n",
    "# print(new_ticket_token)\n",
    "\n",
    "extract(\"ticket\", new_ticket_token)\n",
    "print(len(new_ticket_token))\n",
    "\n",
    "ticket_final = []\n",
    "for i in new_ticket_token:\n",
    "    if i <= 100000:\n",
    "        group = 1\n",
    "    elif i <= 200000:\n",
    "        group = 2\n",
    "    elif i <= 300000:\n",
    "        group = 3\n",
    "    elif i <= 400000:\n",
    "        group = 4\n",
    "    else:\n",
    "        group = 5\n",
    "    ticket_final.append(group)\n",
    "\n",
    "ticket = one_hot_encoding(ticket_final, dummy=False)\n",
    "print(len(ticket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'float' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-33ac6349c890>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# print(cabin_original)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcabin_original\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;34m\"NaN\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcabin_original\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mcabin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'float' is not iterable"
     ]
    }
   ],
   "source": [
    "cabin_original = train_df[\"Cabin\"]\n",
    "cabin = []\n",
    "\n",
    "# print(cabin_original)\n",
    "for i in range(0,len(cabin_original)):\n",
    "    if  in cabin_original[i]:\n",
    "        cabin.append(1)\n",
    "    else:\n",
    "        cabin.append(2)\n",
    "print(cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 42)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate((pclass, X_name, sex, age, sibling, parent, ticket, fare,embarked), axis=1)\n",
    "# X_train = np.concatenate((pclass,), axis=1)\n",
    "# X_train = np.concatenate((X_train, age), axis=1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 3)\n",
      "(891, 5)\n",
      "(891, 2)\n",
      "(891, 8)\n",
      "(891, 7)\n",
      "(891, 7)\n",
      "(891, 5)\n",
      "(891, 2)\n",
      "(891, 3)\n"
     ]
    }
   ],
   "source": [
    "print(pclass.shape)\n",
    "print(X_name.shape)\n",
    "print(sex.shape)\n",
    "print(age.shape)\n",
    "print(sibling.shape)\n",
    "print(parent.shape)\n",
    "print(ticket.shape)\n",
    "print(fare.shape)\n",
    "# print(cabin.shape)\n",
    "print(embarked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      "  1 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      "  1 0 1 0 0]\n",
      " [0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      "  1 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      "  1 0 0 0 1]\n",
      " [0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      "  1 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_df[\"Name\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
